{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrbjfUItCAOm"
      },
      "source": [
        "I work with Zichuan Li and Yichen Liu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpUUK_SHCVTe",
        "outputId": "75ea1e96-c8c6-4ba6-dc31-c61594398814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorboardX\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "# from tensorboardX import SummaryWriter\n",
        "\n",
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 1024\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.CIFAR10('cifar10_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.CIFAR10('cifar10_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLQlNRXlOTrc",
        "outputId": "41fb03a2-6f31-4bb3-a35e-70875f02a2ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no input normalization\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def tp_relu(x, delta=1.):\n",
        "    ind1 = (x < -1. * delta).float()\n",
        "    ind2 = (x > delta).float()\n",
        "    return .5 * (x + delta) * (1 - ind1) * (1 - ind2) + x * ind2\n",
        "\n",
        "def tp_smoothed_relu(x, delta=1.):\n",
        "    ind1 = (x < -1. * delta).float()\n",
        "    ind2 = (x > delta).float()\n",
        "    return (x + delta) ** 2 / (4 * delta) * (1 - ind1) * (1 - ind2) + x * ind2\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def __init__(self, mu, std):\n",
        "        super(Normalize, self).__init__()\n",
        "        self.mu, self.std = mu, std\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (x - self.mu) / self.std\n",
        "\n",
        "class IdentityLayer(nn.Module):\n",
        "    def forward(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "class PreActBlock(nn.Module):\n",
        "    '''Pre-activation version of the BasicBlock.'''\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, bn, learnable_bn, stride=1, activation='relu'):\n",
        "        super(PreActBlock, self).__init__()\n",
        "        self.collect_preact = True\n",
        "        self.activation = activation\n",
        "        self.avg_preacts = []\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes, affine=learnable_bn) if bn else IdentityLayer()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=not learnable_bn)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, affine=learnable_bn) if bn else IdentityLayer()\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=not learnable_bn)\n",
        "\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=not learnable_bn)\n",
        "            )\n",
        "\n",
        "    def act_function(self, preact):\n",
        "        if self.activation == 'relu':\n",
        "            act = F.relu(preact)\n",
        "        elif self.activation[:6] == '3prelu':\n",
        "            act = tp_relu(preact, delta=float(self.activation.split('relu')[1]))\n",
        "        elif self.activation[:8] == '3psmooth':\n",
        "            act = tp_smoothed_relu(preact, delta=float(self.activation.split('smooth')[1]))\n",
        "        else:\n",
        "            assert self.activation[:8] == 'softplus'\n",
        "            beta = int(self.activation.split('softplus')[1])\n",
        "            act = F.softplus(preact, beta=beta)\n",
        "        return act\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.act_function(self.bn1(x))\n",
        "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x  # Important: using out instead of x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(self.act_function(self.bn2(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "class PreActResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, n_cls, cuda=True, half_prec=False,\n",
        "        activation='relu', fts_before_bn=False, normal='none'):\n",
        "        super(PreActResNet, self).__init__()\n",
        "        self.bn = True\n",
        "        self.learnable_bn = True  # doesn't matter if self.bn=False\n",
        "        self.in_planes = 64\n",
        "        self.avg_preact = None\n",
        "        self.activation = activation\n",
        "        self.fts_before_bn = fts_before_bn\n",
        "        if normal == 'cifar10':\n",
        "            self.mu = torch.tensor((0.4914, 0.4822, 0.4465)).view(1, 3, 1, 1)\n",
        "            self.std = torch.tensor((0.2471, 0.2435, 0.2616)).view(1, 3, 1, 1)\n",
        "        else:\n",
        "            self.mu = torch.tensor((0.0, 0.0, 0.0)).view(1, 3, 1, 1)\n",
        "            self.std = torch.tensor((1.0, 1.0, 1.0)).view(1, 3, 1, 1)\n",
        "            print('no input normalization')\n",
        "        if cuda:\n",
        "            self.mu = self.mu.cuda()\n",
        "            self.std = self.std.cuda()\n",
        "        if half_prec:\n",
        "            self.mu = self.mu.half()\n",
        "            self.std = self.std.half()\n",
        "\n",
        "        self.normalize = Normalize(self.mu, self.std)\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=not self.learnable_bn)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.bn = nn.BatchNorm2d(512 * block.expansion)\n",
        "        self.linear = nn.Linear(512*block.expansion, n_cls)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, self.bn, self.learnable_bn, stride, self.activation))\n",
        "            # layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        for layer in [*self.layer1, *self.layer2, *self.layer3, *self.layer4]:\n",
        "            layer.avg_preacts = []\n",
        "\n",
        "        out = self.normalize(x)\n",
        "        out = self.conv1(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        if return_features and self.fts_before_bn:\n",
        "            return out.view(out.size(0), -1)\n",
        "        out = F.relu(self.bn(out))\n",
        "        if return_features:\n",
        "            return out.view(out.size(0), -1)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def PreActResNet18(n_cls, cuda=True, half_prec=False, activation='relu', fts_before_bn=False,\n",
        "    normal='none'):\n",
        "    #print('initializing PA RN-18 with act {}, normal {}'.format())\n",
        "    return PreActResNet(PreActBlock, [2, 2, 2, 2], n_cls=n_cls, cuda=cuda, half_prec=half_prec,\n",
        "        activation=activation, fts_before_bn=fts_before_bn, normal=normal)\n",
        "\n",
        "\n",
        "# intialize the model\n",
        "model = PreActResNet18(10, cuda=True, activation='softplus1').to(device)\n",
        "model.eval()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kVi4B3hFOzv8"
      },
      "outputs": [],
      "source": [
        "def pgd_linf_untargeted(model, x, labels, k, eps, eps_step):\n",
        "    model.eval()\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "    adv_x = x.clone().detach()\n",
        "    adv_x.requires_grad_(True)\n",
        "    for _ in range(k):\n",
        "        adv_x.requires_grad_(True)\n",
        "        model.zero_grad()\n",
        "        output = model(adv_x)\n",
        "        # TODO: Calculate the loss\n",
        "        loss = ce_loss(output, labels)\n",
        "        loss.backward()\n",
        "        # TODO: compute the adv_x\n",
        "        # find delta, clamp with eps\n",
        "\n",
        "        delta = eps_step * adv_x.grad.sign()\n",
        "        delta = torch.clamp(delta, min=-eps, max=eps)\n",
        "\n",
        "        adv_x = adv_x + delta\n",
        "        adv_x = torch.clamp(adv_x, min=0, max=1).detach()\n",
        "\n",
        "        adv_x = adv_x.detach()\n",
        "\n",
        "    return adv_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4o5lI9ONrxv1"
      },
      "outputs": [],
      "source": [
        "def fgsm_linf_untargeted(model, x, labels, eps):\n",
        "    import torch\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    model.eval()\n",
        "    x_adv = x.clone().detach().requires_grad_(True)\n",
        "    logits = model(x_adv)\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    grad = torch.autograd.grad(loss, x_adv)[0]\n",
        "\n",
        "    # One FGSM step\n",
        "    x_adv = x_adv + eps * torch.sign(grad)\n",
        "\n",
        "    # Project to valid pixel range\n",
        "    x_adv = torch.clamp(x_adv, 0.0, 1.0).detach()\n",
        "    return x_adv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76lcFhf8PBhm"
      },
      "source": [
        "#### Adversarial training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FodpSLbPKb4",
        "outputId": "d6e3ef0e-2b30-4c7f-8b7b-52cc8fbb980d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Loaded existing standard model from standard_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36497/1034592343.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_nat.load_state_dict(torch.load(standard_model_path, map_location=device))\n",
            "/tmp/ipykernel_36497/1034592343.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_adv.load_state_dict(torch.load(adv_model_path, map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded existing adversarial model from adv_pgd_eps_4_255_model.pth\n",
            "Loaded existing adversarial model from adv_pgd_eps_8_255_model.pth\n",
            "Loaded existing adversarial model from adv_pgd_eps_16_255_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Device\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Re-init model with CIFAR-10 normalization handled inside the model\n",
        "model = PreActResNet18(10, cuda=use_cuda, activation='softplus1', normal='cifar10').to(device)\n",
        "\n",
        "# Standard training\n",
        "def train_standard(model, train_loader, epochs=2, lr=0.1, weight_decay=5e-4):\n",
        "    import torch.optim as optim\n",
        "    model.train()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[epochs//2, int(0.8*epochs)], gamma=0.1)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total, correct, total_loss = 0, 0, 0.0\n",
        "        pbar = tqdm(train_loader, desc=f\"Standard Train Epoch {ep}/{epochs}\")\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += x.size(0)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            pbar.set_postfix(loss=total_loss/total, acc=correct/total)\n",
        "        scheduler.step()\n",
        "\n",
        "# Adversarial training using PGD\n",
        "def train_adversarial(model, train_loader, epochs=2, lr=0.1, weight_decay=5e-4, pgd_steps=10, eps=8/255.0, eps_step=2/255.0):\n",
        "    import torch.optim as optim\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[epochs//2, int(0.8*epochs)], gamma=0.1)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total, correct, total_loss = 0, 0, 0.0\n",
        "        pbar = tqdm(train_loader, desc=f\"Adv Train Epoch {ep}/{epochs} (eps={eps:.4f})\")\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x_adv = pgd_linf_untargeted(model, x, y, k=pgd_steps, eps=eps, eps_step=eps_step)\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x_adv)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += x.size(0)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            pbar.set_postfix(loss=total_loss/total, acc=correct/total)\n",
        "        scheduler.step()\n",
        "\n",
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def new_model():\n",
        "    return PreActResNet18(10, cuda=use_cuda, activation='softplus1', normal='cifar10').to(device)\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "# Standard training model\n",
        "model_nat = new_model()\n",
        "standard_model_path = \"standard_model.pth\"\n",
        "if os.path.exists(standard_model_path):\n",
        "    model_nat.load_state_dict(torch.load(standard_model_path, map_location=device))\n",
        "    print(f\"Loaded existing standard model from {standard_model_path}\")\n",
        "else:\n",
        "    train_standard(model_nat, train_loader, epochs=10)\n",
        "    save_model(model_nat, standard_model_path)\n",
        "    print(f\"Trained and saved new standard model to {standard_model_path}\")\n",
        "\n",
        "# Experiments for (a) and (b)\n",
        "eps_values = [4/255.0, 8/255.0, 16/255.0]\n",
        "for eps in eps_values:\n",
        "    adv_model_path = f\"adv_pgd_eps_{int(eps*255)}_255_model.pth\"\n",
        "    model_adv = new_model()\n",
        "    if os.path.exists(adv_model_path):\n",
        "        model_adv.load_state_dict(torch.load(adv_model_path, map_location=device))\n",
        "        print(f\"Loaded existing adversarial model from {adv_model_path}\")\n",
        "    else:\n",
        "        train_adversarial(model_adv, train_loader, epochs=10, pgd_steps=10, eps=eps, eps_step=eps/4)\n",
        "        save_model(model_adv, adv_model_path)\n",
        "        print(f\"Trained and saved new adversarial model to {adv_model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvlHJ2WcwSJN",
        "outputId": "7043545e-3e6b-45fa-c53b-9eb92cd4bd88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36497/2143596549.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(path, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model path: standard_model.pth\n",
            "[eps=0, pgd_steps=20] Clean acc:  0.7891\n",
            "[eps=0.03137, pgd_steps=20] Robust acc: 0.0000\n",
            "model path: standard_model.pth\n",
            "[eps=0, pgd_steps=10] Clean acc:  0.7891\n",
            "[eps=0.03137, pgd_steps=10] Robust acc: 0.0000\n",
            "model path: standard_model.pth\n",
            "[eps=0, pgd_steps=4] Clean acc:  0.7891\n",
            "[eps=0.03137, pgd_steps=4] Robust acc: 0.0002\n",
            "model path: adv_pgd_eps_4_255_model.pth\n",
            "[eps=0, pgd_steps=20] Clean acc:  0.5137\n",
            "[eps=0.03137, pgd_steps=20] Robust acc: 0.0239\n",
            "model path: adv_pgd_eps_4_255_model.pth\n",
            "[eps=0, pgd_steps=10] Clean acc:  0.5137\n",
            "[eps=0.03137, pgd_steps=10] Robust acc: 0.1550\n",
            "model path: adv_pgd_eps_4_255_model.pth\n",
            "[eps=0, pgd_steps=4] Clean acc:  0.5137\n",
            "[eps=0.03137, pgd_steps=4] Robust acc: 0.3611\n",
            "model path: adv_pgd_eps_8_255_model.pth\n",
            "[eps=0, pgd_steps=20] Clean acc:  0.3229\n",
            "[eps=0.03137, pgd_steps=20] Robust acc: 0.1165\n",
            "model path: adv_pgd_eps_8_255_model.pth\n",
            "[eps=0, pgd_steps=10] Clean acc:  0.3229\n",
            "[eps=0.03137, pgd_steps=10] Robust acc: 0.2073\n",
            "model path: adv_pgd_eps_8_255_model.pth\n",
            "[eps=0, pgd_steps=4] Clean acc:  0.3229\n",
            "[eps=0.03137, pgd_steps=4] Robust acc: 0.2714\n",
            "model path: adv_pgd_eps_16_255_model.pth\n",
            "[eps=0, pgd_steps=20] Clean acc:  0.1000\n",
            "[eps=0.03137, pgd_steps=20] Robust acc: 0.1000\n",
            "model path: adv_pgd_eps_16_255_model.pth\n",
            "[eps=0, pgd_steps=10] Clean acc:  0.1000\n",
            "[eps=0.03137, pgd_steps=10] Robust acc: 0.1000\n",
            "model path: adv_pgd_eps_16_255_model.pth\n",
            "[eps=0, pgd_steps=4] Clean acc:  0.1000\n",
            "[eps=0.03137, pgd_steps=4] Robust acc: 0.1000\n"
          ]
        }
      ],
      "source": [
        "def load_model(path):\n",
        "    model = PreActResNet18(10, cuda=use_cuda, activation='softplus1', normal='cifar10').to(device)\n",
        "    state = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n",
        "\n",
        "# Evaluation: standard accuracy\n",
        "@torch.no_grad()\n",
        "def evaluate_standard(model, loader):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        pred = logits.argmax(1)\n",
        "        total += x.size(0)\n",
        "        correct += (pred == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Evaluation: robust accuracy under PGD\n",
        "def evaluate_robust_pgd(model, loader, pgd_steps=10, eps=8/255.0, eps_step=2/255.0):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = pgd_linf_untargeted(model, x, y, k=pgd_steps, eps=eps, eps_step=eps_step)\n",
        "        with torch.no_grad():\n",
        "            logits = model(x_adv)\n",
        "            pred = logits.argmax(1)\n",
        "        total += x.size(0)\n",
        "        correct += (pred == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Evaluation: robust accuracy under FGSM\n",
        "def evaluate_robust_fgsm(model, loader, eps=8/255.0):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = fgsm_linf_untargeted(model, x, y, eps=eps)\n",
        "        with torch.no_grad():\n",
        "            logits = model(x_adv)\n",
        "            pred = logits.argmax(1)\n",
        "        total += x.size(0)\n",
        "        correct += (pred == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "eps_values = [0.0, 8/255.0]\n",
        "\n",
        "model_paths = [\n",
        "    \"standard_model.pth\",\n",
        "    \"adv_pgd_eps_4_255_model.pth\",\n",
        "    \"adv_pgd_eps_8_255_model.pth\",\n",
        "    \"adv_pgd_eps_16_255_model.pth\",\n",
        "]\n",
        "\n",
        "def report_model(path, eps_list, pgd_steps=20):\n",
        "    model = load_model(path)\n",
        "    print(f\"model path: {path}\")\n",
        "\n",
        "    for eps in eps_list:\n",
        "        # PGD robustness\n",
        "        acc = evaluate_robust_pgd(model, test_loader, pgd_steps=pgd_steps, eps=eps, eps_step=(eps/4 if eps>0 else 0.0))\n",
        "\n",
        "        if eps == 0.0:\n",
        "            print(f\"[eps=0, pgd_steps={pgd_steps:d}] Clean acc:  {acc:.4f}\")\n",
        "        else:\n",
        "            print(f\"[eps={eps:.5f}, pgd_steps={pgd_steps:d}] Robust acc: {acc:.4f}\")\n",
        "\n",
        "\n",
        "# Run reports\n",
        "for path in model_paths:\n",
        "    report_model(path, eps_values, 20)\n",
        "    report_model(path, eps_values, 10)\n",
        "    report_model(path, eps_values, 4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uXT2-A7tqQpo"
      },
      "outputs": [],
      "source": [
        "def test_model_on_single_attack(model, attack='pgd_linf', eps=0.1):\n",
        "    model.eval()\n",
        "    tot_test, tot_acc, tot_acc_adv = 0.0, 0.0, 0.0\n",
        "    for batch_idx, (x_batch, y_batch) in tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Evaluating\"):\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        if attack == 'pgd_linf':\n",
        "            # TODO: get x_adv untargeted pgd linf with eps, and eps_step=eps/4\n",
        "            x_adv = pgd_linf_untargeted(model, x_batch, y_batch, 4, eps, eps/4)\n",
        "        elif attack == 'fgsm':\n",
        "            x_adv = fgsm_linf_untargeted(model, x_batch, y_batch, eps)\n",
        "        # elif attack == 'pgd_l2':\n",
        "        #     # TODO: get x_adv untargeted pgd l2 with eps, and eps_step=eps/4\n",
        "        #     x_adv = pgd_l2_untargeted(model, x_batch, y_batch, 4, eps, eps/4)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        # get the testing accuracy and update tot_test and tot_acc\n",
        "        out_std = model(x_batch)\n",
        "        pred_std = torch.max(out_std, dim=1)[1]\n",
        "\n",
        "        out_adv = model(x_adv)\n",
        "        pred_adv = torch.max(out_adv, dim=1)[1]\n",
        "        tot_acc_adv += (pred_adv == y_batch).sum().item()\n",
        "        tot_acc += (pred_std == y_batch).sum().item()\n",
        "\n",
        "        tot_test += x_batch.size(0)\n",
        "\n",
        "    print('Standard accuracy %.5lf' % (tot_acc/tot_test))\n",
        "    print('Robust accuracy %.5lf' % (tot_acc_adv/tot_test), f'on {attack} attack with eps = {eps}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vxmCuhOtzqK",
        "outputId": "c0853e05-88a3-4d90-9fd8-5c9daeb0ed58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36497/1688059915.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
            "Evaluating: 100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n",
            "/tmp/ipykernel_36497/1688059915.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.78910\n",
            "Robust accuracy 0.00020 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:05<00:00,  1.90it/s]\n",
            "/tmp/ipykernel_36497/1688059915.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.51370\n",
            "Robust accuracy 0.36110 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:05<00:00,  1.91it/s]\n",
            "/tmp/ipykernel_36497/1688059915.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.32290\n",
            "Robust accuracy 0.27140 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:05<00:00,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# PGD linf with eps = 8/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on Linf attack with model 1 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 2 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 3 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 4 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t97KUdggt8BN",
        "outputId": "3989ed45-7c96-41f8-a19f-82227028c76c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36497/1383628637.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
            "Evaluating: 100%|██████████| 10/10 [00:05<00:00,  1.89it/s]\n",
            "/tmp/ipykernel_36497/1383628637.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.78910\n",
            "Robust accuracy 0.05110 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:05<00:00,  1.88it/s]\n",
            "/tmp/ipykernel_36497/1383628637.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.51370\n",
            "Robust accuracy 0.43850 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:05<00:00,  1.88it/s]\n",
            "/tmp/ipykernel_36497/1383628637.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.32290\n",
            "Robust accuracy 0.29680 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:05<00:00,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# PGD linf with eps = 4/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on Linf attack with model 1 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 2 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 3 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 4 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0bbjk0hBUaq",
        "outputId": "d4656479-e0d6-4c83-f8e5-a480aa11e8d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36497/1997435729.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
            "Evaluating: 100%|██████████| 10/10 [00:02<00:00,  4.65it/s]\n",
            "/tmp/ipykernel_36497/1997435729.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.78910\n",
            "Robust accuracy 0.02040 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:02<00:00,  4.65it/s]\n",
            "/tmp/ipykernel_36497/1997435729.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.51370\n",
            "Robust accuracy 0.36250 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:02<00:00,  4.64it/s]\n",
            "/tmp/ipykernel_36497/1997435729.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.32290\n",
            "Robust accuracy 0.27110 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:02<00:00,  4.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# fgsm with eps = 8/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on fgsm attack with model 1 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 2 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 3 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 4 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXssudQRBOto",
        "outputId": "c92e0048-6439-4892-9004-5c43735f4c4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36497/4231971677.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
            "Evaluating: 100%|██████████| 10/10 [00:02<00:00,  4.67it/s]\n",
            "/tmp/ipykernel_36497/4231971677.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.78910\n",
            "Robust accuracy 0.10140 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:02<00:00,  4.77it/s]\n",
            "/tmp/ipykernel_36497/4231971677.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.51370\n",
            "Robust accuracy 0.43830 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:02<00:00,  4.78it/s]\n",
            "/tmp/ipykernel_36497/4231971677.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.32290\n",
            "Robust accuracy 0.29690 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 10/10 [00:02<00:00,  4.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# fgsm with eps = 4/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on fgsm attack with model 1 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 2 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 3 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 4 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
