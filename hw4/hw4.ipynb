{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaw8lco5ixow",
        "outputId": "e70d7771-9810-4db8-b1ba-a2ede7696e2a"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransforms\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Load the pre-trained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Define the image preprocessing transformations\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Load the ImageNet class index mapping\n",
        "with open(\"imagenet_class_index.json\") as f:\n",
        "    class_idx = json.load(f)\n",
        "idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
        "idx2synset = [class_idx[str(k)][0] for k in range(len(class_idx))]\n",
        "id2label = {v[0]: v[1] for v in class_idx.values()}\n",
        "\n",
        "imagenet_path = './imagenet_samples'\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = os.listdir(imagenet_path)\n",
        "\n",
        "\n",
        "for img_path in image_paths:\n",
        "    # Open and preprocess the image\n",
        "    my_img = os.path.join(imagenet_path, img_path)\n",
        "    input_image = Image.open(my_img).convert('RGB')\n",
        "    input_tensor = preprocess(input_image)\n",
        "    input_batch = input_tensor.unsqueeze(0)  # Create a mini-batch as expected by the model\n",
        "\n",
        "    # Move the input and model to GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "        input_batch = input_batch.to('cuda')\n",
        "        model.to('cuda')\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "\n",
        "    # Get the predicted class index\n",
        "    _, predicted_idx = torch.max(output, 1)\n",
        "    predicted_idx = predicted_idx.item()\n",
        "    predicted_synset = idx2synset[predicted_idx]\n",
        "    predicted_label = idx2label[predicted_idx]\n",
        "\n",
        "    print(f\"Predicted label: {predicted_synset} ({predicted_label})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRtOaUyPi2kO"
      },
      "outputs": [],
      "source": [
        "from skimage.segmentation import slic\n",
        "import numpy as np\n",
        "\n",
        "def lime_explain(model, pil_img, target_class, num_segments=50, num_samples=5000, sigma=0.25):\n",
        "    img = np.array(pil_img.resize((224, 224))) / 255.0\n",
        "    segments = slic(img, n_segments=num_segments, compactness=10, sigma=1)\n",
        "    num_features = len(np.unique(segments))\n",
        "    masks = np.random.randint(0, 2, size=(num_samples, num_features))\n",
        "    masks[0] = 1\n",
        "\n",
        "    segment_means = {}\n",
        "    for seg_id in range(num_features):\n",
        "        mask = segments == seg_id\n",
        "        segment_means[seg_id] = img[mask].mean(axis=0)\n",
        "\n",
        "    img_mean = img.mean(axis=(0, 1))\n",
        "    preds = []\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "    if device.type == 'cuda':\n",
        "        mean = mean.cuda()\n",
        "        std = std.cuda()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for mask in masks:\n",
        "        # Create perturbed image\n",
        "        perturbed_img = img.copy()\n",
        "\n",
        "        for seg_id in range(num_features):\n",
        "            if mask[seg_id] == 0:\n",
        "                mask_region = segments == seg_id\n",
        "                # mask the region to gray color\n",
        "                perturbed_img[mask_region] = 0.5\n",
        "\n",
        "        tensor = torch.tensor(perturbed_img.transpose(2, 0, 1)).float().unsqueeze(0)\n",
        "\n",
        "        if device.type == 'cuda':\n",
        "            tensor = tensor.cuda()\n",
        "        tensor = (tensor - mean) / std\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(tensor)\n",
        "            probs = torch.nn.functional.softmax(output, dim=1)\n",
        "            preds.append(probs[0, target_class].cpu().item())\n",
        "\n",
        "    preds = np.array(preds)\n",
        "\n",
        "    original = np.ones(num_features)\n",
        "    distances = np.sum(np.abs(masks - original), axis=1) / num_features\n",
        "\n",
        "    kernel_width = sigma * np.sqrt(num_features) * 0.75\n",
        "    weights = np.exp(-(distances ** 2) / (kernel_width ** 2))\n",
        "\n",
        "    X = np.column_stack([np.ones(num_samples), masks])\n",
        "    W = np.diag(weights)\n",
        "    y = preds\n",
        "\n",
        "    XtWX = X.T @ W @ X\n",
        "    XtWX = XtWX + 1e-6 * np.eye(X.shape[1])\n",
        "    XtWy = X.T @ W @ y\n",
        "\n",
        "    try:\n",
        "        coef = np.linalg.solve(XtWX, XtWy)\n",
        "    except np.linalg.LinAlgError:\n",
        "        coef = np.linalg.pinv(XtWX) @ XtWy\n",
        "\n",
        "    feature_importance = coef[1:]\n",
        "\n",
        "    importance_map = np.zeros_like(segments, dtype=float)\n",
        "    for seg_id in range(num_features):\n",
        "        importance_map[segments == seg_id] = feature_importance[seg_id]\n",
        "\n",
        "    return importance_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq8pVZ5ge--5"
      },
      "outputs": [],
      "source": [
        "def smoothgrad_explain(model, input_tensor, target_class, n_samples=50, sigma=0.15):\n",
        "    device = next(model.parameters()).device\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "    grads = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        noise = sigma * torch.randn_like(input_tensor)\n",
        "        noisy_input = input_tensor + noise\n",
        "        noisy_input = noisy_input.unsqueeze(0)\n",
        "        noisy_input.requires_grad_()\n",
        "\n",
        "        output = model(noisy_input)\n",
        "        loss = output[0, target_class]\n",
        "        loss.backward()\n",
        "\n",
        "        grads.append(noisy_input.grad.detach()[0])\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_grad = torch.mean(torch.stack(grads), dim=0)\n",
        "    saliency = avg_grad.abs().mean(dim=0).cpu().numpy()  # [224,224]\n",
        "    return saliency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xwgSKPr24buz",
        "outputId": "57bbcc93-73c8-4b5a-e6e6-884bd6edbb54"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import kendalltau, spearmanr\n",
        "\n",
        "for img_path in image_paths:\n",
        "    # Open and preprocess the image\n",
        "    print(img_path)\n",
        "    my_img = os.path.join(imagenet_path, img_path)\n",
        "    input_image = Image.open(my_img).convert('RGB')\n",
        "\n",
        "    input_tensor = preprocess(input_image)\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "    if torch.cuda.is_available():\n",
        "        input_batch = input_batch.to('cuda')\n",
        "        model.to('cuda')\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "\n",
        "    # Get the predicted class index\n",
        "    _, predicted_idx = torch.max(output, 1)\n",
        "    predicted_idx = predicted_idx.item()\n",
        "    predicted_synset = idx2synset[predicted_idx]\n",
        "    predicted_label = idx2label[predicted_idx]\n",
        "\n",
        "\n",
        "    # calculate attr with two methods\n",
        "    lime_attr = lime_explain(model, input_image, predicted_idx)\n",
        "    #lime_norm = (lime_attr - lime_attr.min()) / (lime_attr.max() - lime_attr.min())\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        input_tensor = input_tensor.to('cuda')\n",
        "\n",
        "    smooth_attr = smoothgrad_explain(model, input_tensor, predicted_idx)\n",
        "    #smooth_norm = (smooth_attr - smooth_attr.min()) / (smooth_attr.max() - smooth_attr.min())\n",
        "\n",
        "    lime_vals = lime_attr.flatten()\n",
        "    smooth_vals = smooth_attr.flatten()\n",
        "    spearman_corr, _ = spearmanr(lime_vals, smooth_vals)\n",
        "    kendall_corr, _ = kendalltau(lime_vals, smooth_vals)\n",
        "\n",
        "    print(f\"Spearman correlation: {spearman_corr:.3f}\")\n",
        "    print(f\"Kendall-Tau correlation: {kendall_corr:.3f}\")\n",
        "\n",
        "\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    axs[0].imshow(input_image.resize((224, 224)))\n",
        "    axs[0].set_title(f\"Original ({idx2label[predicted_idx]})\")\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    axs[1].imshow(input_image.resize((224, 224)))\n",
        "    lime_img = axs[1].imshow(lime_attr, cmap='hot', alpha=0.9)\n",
        "    axs[1].set_title(\"LIME Explanation\")\n",
        "    axs[1].axis('off')\n",
        "    plt.colorbar(lime_img, ax=axs[1], fraction=0.05)\n",
        "\n",
        "\n",
        "    axs[2].imshow(input_image.resize((224, 224)))\n",
        "    smooth_img = axs[2].imshow(smooth_attr, cmap='hot', alpha=0.9)\n",
        "    axs[2].set_title(\"SmoothGrad Explanation\")\n",
        "    axs[2].axis('off')\n",
        "    plt.colorbar(smooth_img, ax=axs[2], fraction=0.05)\n",
        "\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMJ2gwXJfotO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyN42wpWh+VO4AbdMxcankPb",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
